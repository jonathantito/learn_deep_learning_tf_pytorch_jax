{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una capa simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una capa (layer) en una red neuronal (NN - Neural network) es un grupo de neuronas (**tipicamente pero no siempre** tenemos más de una neurona en una capa)\n",
    "\n",
    "- Entrada (Input) para la capa (layer) -> datos de entrenamiento o la salida de la capa previa\n",
    "\n",
    "- Cada neurona tiene sus únicos pesos (weights) y sesgos (bias)\n",
    "\n",
    "## Ejemplos de capas de una sola neurona\n",
    "\n",
    "### Regresión lineal simple\n",
    "\n",
    "Ejemplo práctico: Predecir el precio de una casa basado únicamente en su tamaño.\n",
    "Justificación: En este caso, una sola neurona puede modelar la relación lineal entre el tamaño de la casa (entrada) y su precio (salida). La neurona aprenderá el peso adecuado para la entrada y el sesgo para ajustar la línea de regresión.\n",
    "\n",
    "### Clasificación binaria simple\n",
    "\n",
    "Ejemplo práctico: Determinar si un correo electrónico es spam o no spam.\n",
    "Justificación: Una sola neurona puede aprender a clasificar entre dos categorías. La salida de la neurona (después de pasar por una función de activación como la sigmoide) representará la probabilidad de que el correo sea spam.\n",
    "\n",
    "### Detección de umbral\n",
    "\n",
    "Ejemplo práctico: Activar una alarma cuando la temperatura de un sistema supera cierto nivel.\n",
    "Justificación: Una neurona puede aprender el umbral apropiado y activarse cuando la entrada (temperatura) supere ese umbral, simulando un sistema de alarma simple.\n",
    "\n",
    "### Puerta lógica AND o OR\n",
    "\n",
    "Ejemplo práctico: Implementar una puerta lógica AND o OR en un circuito neuronal simple.\n",
    "Justificación: Una sola neurona puede aprender los pesos y el sesgo necesarios para replicar el comportamiento de estas puertas lógicas básicas, demostrando cómo las redes neuronales pueden modelar operaciones lógicas.\n",
    "\n",
    "### Análisis de sentimiento básico\n",
    "\n",
    "Ejemplo práctico: Clasificar una reseña de producto como positiva o negativa basándose en palabras clave.\n",
    "Justificación: Para un análisis muy básico, una neurona podría aprender a asignar pesos a ciertas palabras clave y producir una salida que indique si el sentimiento general es positivo o negativo.\n",
    "\n",
    "### Predicción de tendencia simple\n",
    "\n",
    "Ejemplo práctico: Predecir si el precio de una acción subirá o bajará basándose en un indicador técnico simple.\n",
    "Justificación: Una neurona podría aprender a interpretar un solo indicador técnico (como una media móvil) y predecir la dirección del movimiento del precio.\n",
    "\n",
    "### Conversión de unidades\n",
    "\n",
    "Ejemplo práctico: Convertir grados Celsius a Fahrenheit.\n",
    "Justificación: Aunque esto normalmente se haría con una fórmula directa, una sola neurona podría aprender la relación lineal entre estas escalas de temperatura, demostrando cómo las redes neuronales pueden aprender transformaciones lineales.\n",
    "\n",
    "### Filtro de señal simple\n",
    "\n",
    "Ejemplo práctico: Detectar picos en una señal de audio.\n",
    "Justificación: Una neurona podría aprender a activarse cuando la amplitud de la señal supera cierto umbral, actuando como un detector de picos básico.\n",
    "\n",
    "### Estimación de propina\n",
    "\n",
    "Ejemplo práctico: Calcular la propina recomendada basándose en el total de la cuenta en un restaurante.\n",
    "Justificación: Una neurona podría aprender la relación típica entre el total de la cuenta y la propina esperada, proporcionando una estimación simple.\n",
    "\n",
    "### Control de brillo automático\n",
    "\n",
    "Ejemplo práctico: Ajustar el brillo de una pantalla basándose en la luz ambiental.\n",
    "Justificación: Una neurona podría aprender a mapear los niveles de luz ambiental a los niveles apropiados de brillo de la pantalla, proporcionando un control automático simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importaciones\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entradas (Inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de entradas (inputs) y pesos (weights)\n",
    "N = 5\n",
    "secure_random = random.SystemRandom()\n",
    "inputs = secure_random.sample(range(1, 100), N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona 1 de la capa (layer) 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53, 0.63, 0.1, -0.9, 0.02]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights_n1 = [x/100 for x in secure_random.sample(range(-100, 100), N)]\n",
    "print(weights_n1)\n",
    "bias_n1 = secure_random.sample(range(1, 10),1)[0]\n",
    "print(bias_n1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona 2 de la capa (layer) 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79, 0.31, -0.26, -0.52, 0.65]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "weights_n2 = [x/100 for x in secure_random.sample(range(-100, 100), N)]\n",
    "print(weights_n2)\n",
    "bias_n2 = secure_random.sample(range(1, 10),1)[0]\n",
    "print(bias_n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona 3 de la capa (layer) 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.33, 0.64, -1.0, 0.44]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "weights_n3 = [x/100 for x in secure_random.sample(range(-100, 100), N)]\n",
    "print(weights_n3)\n",
    "bias_n3 = secure_random.sample(range(1, 10),1)[0]\n",
    "print(bias_n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salida (Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=np.dot(inputs,weights_n1),np.dot(inputs,weights_n2),np.dot(inputs,weights_n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.53000000000001, 62.21, 12.060000000000002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red neuronal completamente conectada (fully connected): cada neurona de la capa actual tiene conexiones con cada neurona de la capa anterior. Este es un tipo de red neuronal muy común, pero cabe señalar que no es necesario conectar todo completamente de esta manera, se suelen utilizar cuando es necesario entender el \"panorama completo\" del problema. A continuación algunos ejemplos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación de imágenes\n",
    "\n",
    "Ejemplo práctico: Reconocimiento de dígitos escritos a mano (MNIST dataset).\n",
    "Justificación: Después de las capas convolucionales que extraen características, se usan capas totalmente conectadas para:\n",
    "\n",
    "Combinar características de alto nivel.\n",
    "Aprender relaciones no lineales entre estas características.\n",
    "Mapear estas características al espacio de clasificación final (10 clases para MNIST).\n",
    "\n",
    "Las capas totalmente conectadas permiten que la red aprenda patrones complejos que no son necesariamente locales o jerárquicos, lo cual es crucial para la clasificación final.\n",
    "\n",
    "\n",
    "Patrones locales: Son características o relaciones que existen en una región específica y limitada de los datos.\n",
    "\n",
    "\n",
    "Patrones jerárquicos: Son características que se construyen de manera progresiva, donde las características de nivel superior se componen de características de nivel inferior.\n",
    "\n",
    "\n",
    "Patrones complejos no locales o no jerárquicos: Son relaciones o características que involucran múltiples aspectos de los datos, posiblemente distantes o aparentemente no relacionados, y que no siguen una estructura jerárquica simple.\n",
    "\n",
    "\n",
    "Imagine una red neuronal que compone música:\n",
    "\n",
    "Patrones locales: Identificar notas o acordes individuales.\n",
    "Patrones jerárquicos: Combinar notas para formar melodías o progresiones de acordes.\n",
    "Patrones complejos no locales: Crear una estructura musical coherente a lo largo de toda una pieza, con temas recurrentes, desarrollo de motivos y resolución armónica. Esto requiere \"entender\" la pieza en su totalidad, no solo secciones individuales.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pronóstico de series temporales\n",
    "\n",
    "Ejemplo práctico: Predicción de ventas futuras basada en datos históricos.\n",
    "Justificación: Después de procesar la secuencia temporal con capas recurrentes, se usan capas totalmente conectadas para:\n",
    "\n",
    "Combinar información de diferentes escalas temporales.\n",
    "Aprender relaciones no lineales entre variables.\n",
    "Mapear las características extraídas a las predicciones futuras.\n",
    "\n",
    "Las capas totalmente conectadas permiten que la red aprenda patrones complejos que pueden no ser capturados por modelos lineales tradicionales de series temporales.\n",
    "\n",
    "\n",
    "Las capas recurrentes son un tipo de capa en las redes neuronales diseñadas específicamente para procesar secuencias de datos. A diferencia de las capas feed-forward tradicionales, las capas recurrentes tienen conexiones que les permiten \"recordar\" información de pasos anteriores. Esto las hace particularmente útiles para tareas que involucran datos secuenciales, como texto, series temporales, o audio.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Redes generativas adversarias (GANs)\n",
    "\n",
    "Ejemplo práctico: Generación de imágenes realistas de rostros.\n",
    "Justificación: Tanto en el generador como en el discriminador, se utilizan capas totalmente conectadas para:\n",
    "\n",
    "En el generador: mapear el espacio latente a características de imagen de alto nivel.\n",
    "En el discriminador: combinar características para tomar la decisión final sobre la autenticidad de la imagen.\n",
    "\n",
    "Las capas totalmente conectadas permiten que ambas redes aprendan transformaciones complejas necesarias para generar y discriminar imágenes realistas.\n",
    "\n",
    "\n",
    "El espacio latente, también conocido como espacio oculto o espacio de características, es una representación comprimida y abstracta de los datos de entrada. Es un espacio de menor dimensión donde se capturan las características esenciales de los datos originales.\n",
    "Imaginemos el espacio latente como un \"mundo simplificado\" donde las características más importantes de nuestros datos están representadas de manera compacta.\n",
    "Ejemplo didáctico:\n",
    "\n",
    "\n",
    "\n",
    "Imaginemos un espacio latente para recetas de cocina con 4 dimensiones:\n",
    "\n",
    "W: dulzura (0 a 1)\n",
    "X: picante (0 a 1)\n",
    "Y: complejidad (0 a 1)\n",
    "Z: tiempo de preparación (0 a 1, donde 0 es rápido y 1 es lento)\n",
    "\n",
    "Una receta representada como (0.8, 0.1, 0.5, 0.3) sería muy dulce, poco picante, de complejidad media y preparación relativamente rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capa (layer) 2 con N neuronas completamente conectadas (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
